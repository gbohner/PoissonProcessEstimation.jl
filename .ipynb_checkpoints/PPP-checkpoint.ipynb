{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating firing rates from neural rasters\n",
    "\n",
    "### Data: \n",
    "N trials (length T), M neurons, {$t_{m,i}^n$} spike times for neuron M on trial N\n",
    "\n",
    "### Model:\n",
    "* D latent functions over [0, T], each function is in an RKHS with kernel $k_d$\n",
    "\n",
    "$$ x^n_d(t) = \\sum_{j=1}^J \\alpha_{d,j}^n k_d(t, u^d_j) $$\n",
    "\n",
    "* $\\mathbf{C} \\in \\mathsf{R}^{M\\times D}$ maps the vector of latent functions drawn for trial n $\\mathbf{x}^n$ into neural space\n",
    "\n",
    "* $\\mathbf{b} \\in \\mathsf{R}^M_+$ is the log mean firing rate for neurons.\n",
    "\n",
    "* There is a non-linearity between the linear combination of latent functions, and firing rates $\\mathbf{\\lambda}_m^n(t)$\n",
    "\n",
    "$$ \\lambda_m^n(t) = e^{\\mathbf{C}\\mathbf{x}^n(t) + \\mathbf{b}} $$\n",
    "\n",
    "\n",
    "### Log-likelihood\n",
    "$\\log p(y | \\lambda) = \\sum_{m,n,i}\\log\\lambda_m^n(t_{m,i}^n) - \\int_t \\lambda_m^n(t) dt$\n",
    "\n",
    "### Score function with penalties\n",
    "\n",
    "$$ \\mathcal{J}(\\mathbf{C}, \\alpha, u) = \\\\ \\\\\n",
    " \\text{Score objective:} \\\\ \\\\\n",
    " \\sum_{m,n,i} [ (\\sum_d C_{md} \\sum_j \\alpha_{d,j}^n \\nabla_t k_d(t_{m,i}^n, u^d_j))^2 \\\\\n",
    " + \\sum_d C_{md} \\sum_j \\alpha_{d,j}^n (\\nabla_t)^2 k_d(t_{m,i}^n, u^d_j) ] \\\\\n",
    " \\text{RKHS smoothness:} \\\\\n",
    "+ \\eta_\\text{RKHS} \\sum_{n,d} \\| x_d^n(t) \\|_\\text{RKHS} \\\\\n",
    " \\text{Loading matrix penalty} \\\\\n",
    " + \\eta_\\text{loading} \\sum_m \\| C_{m,\\cdot} \\|_p \n",
    " $$\n",
    " \n",
    " \n",
    " Different choices of the $p$-norm entail different penalty types for C:\n",
    " * $p=0$ - sparsity\n",
    " * $p=1$ - semi-sparse\n",
    " * $p=2$ - limited power\n",
    " * $p=\\infty$ - limited maximal contribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel choices\n",
    "\n",
    "In order to evaluate the score matching objective, we need to be able to cheaply evaluate the time-derivatives of kernels around the data points.\n",
    "\n",
    "Different kernels mean different interpretations. We want to design the D individual kernels such that the row space of $\\mathbf{C}$ mapping from the individual RKHSs is interpretable biologically.\n",
    "\n",
    "Certain kernels are useful to represent certain behavior:\n",
    "* Gaussian (RBF) kernel - Different $\\sigma$s represent frequency bands\n",
    "* Linear / polinomial kernel - Represents trends in the data ?\n",
    "* Sobolev-like kernel - Possibly frequency band limited -> Frequency content of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import GPflow\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData():\n",
    "    rng = np.random.RandomState( 1 )\n",
    "    N = 30\n",
    "    X = rng.rand(N,1)\n",
    "    Y = np.sin(12*X) + 0.66*np.cos(25*X) + rng.randn(N,1)*0.1 + 3\n",
    "    return X,Y\n",
    "    \n",
    "def getRegressionModel(X,Y):\n",
    "    #build the GPR object\n",
    "    k = GPflow.kernels.Matern52(1)\n",
    "    meanf = GPflow.mean_functions.Linear(1,0)\n",
    "    m = GPflow.gpr.GPR(X, Y, k, meanf)\n",
    "    m.likelihood.variance = 0.01\n",
    "    print \"Here are the parameters before optimization\"\n",
    "    m\n",
    "    return m\n",
    "\n",
    "def optimizeModel(m):\n",
    "    m.optimize()\n",
    "    print \"Here are the parameters after optimization\"\n",
    "    m\n",
    "\n",
    "def setModelPriors( m ):\n",
    "    #we'll choose rather arbitrary priors. \n",
    "    m.kern.lengthscales.prior = GPflow.priors.Gamma(1., 1.)\n",
    "    m.kern.variance.prior = GPflow.priors.Gamma(1., 1.)\n",
    "    m.likelihood.variance.prior = GPflow.priors.Gamma(1., 1.)\n",
    "    m.mean_function.A.prior = GPflow.priors.Gaussian(0., 10.)\n",
    "    m.mean_function.b.prior = GPflow.priors.Gaussian(0., 10.)\n",
    "    print \"model with priors \", m\n",
    "\n",
    "def getSamples( m ):\n",
    "    samples = m.sample(100, epsilon = 0.1)\n",
    "    return samples\n",
    "\n",
    "def runExperiments(plotting=True,outputGraphs=False):\n",
    "    X,Y = getData()\n",
    "    m = getRegressionModel(X,Y)\n",
    "    optimizeModel(m)\n",
    "    setModelPriors( m )\n",
    "    samples = getSamples( m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the parameters before optimization\n",
      "compiling tensorflow function...\n",
      "done\n",
      "optimization terminated, setting model state\n",
      "Here are the parameters after optimization\n",
      "model with priors  model.kern.\u001b[1mvariance\u001b[0m transform:+ve prior:Ga([ 1.],[ 1.])\n",
      "[ 0.70960348]\n",
      "model.kern.\u001b[1mlengthscales\u001b[0m transform:+ve prior:Ga([ 1.],[ 1.])\n",
      "[ 0.08786933]\n",
      "model.likelihood.\u001b[1mvariance\u001b[0m transform:+ve prior:Ga([ 1.],[ 1.])\n",
      "[ 0.0057672]\n",
      "model.mean_function.\u001b[1mA\u001b[0m transform:(none) prior:N([ 0.],[ 10.])\n",
      "[[-0.75312107]]\n",
      "model.mean_function.\u001b[1mb\u001b[0m transform:(none) prior:N([ 0.],[ 10.])\n",
      "[ 3.39353417]\n",
      "compiling tensorflow function...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    runExperiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.17022005e-01],\n",
       "       [  7.20324493e-01],\n",
       "       [  1.14374817e-04],\n",
       "       [  3.02332573e-01],\n",
       "       [  1.46755891e-01],\n",
       "       [  9.23385948e-02],\n",
       "       [  1.86260211e-01],\n",
       "       [  3.45560727e-01],\n",
       "       [  3.96767474e-01],\n",
       "       [  5.38816734e-01],\n",
       "       [  4.19194514e-01],\n",
       "       [  6.85219500e-01],\n",
       "       [  2.04452250e-01],\n",
       "       [  8.78117436e-01],\n",
       "       [  2.73875932e-02],\n",
       "       [  6.70467510e-01],\n",
       "       [  4.17304802e-01],\n",
       "       [  5.58689828e-01],\n",
       "       [  1.40386939e-01],\n",
       "       [  1.98101489e-01],\n",
       "       [  8.00744569e-01],\n",
       "       [  9.68261576e-01],\n",
       "       [  3.13424178e-01],\n",
       "       [  6.92322616e-01],\n",
       "       [  8.76389152e-01],\n",
       "       [  8.94606664e-01],\n",
       "       [  8.50442114e-02],\n",
       "       [  3.90547832e-02],\n",
       "       [  1.69830420e-01],\n",
       "       [  8.78142503e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
